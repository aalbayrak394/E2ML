{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb72d03",
   "metadata": {},
   "source": [
    "# Foundations of Stochastic\n",
    "\n",
    "In this notebook, we will intensify our knowledge about the foundations of stochastic. \n",
    "\n",
    "At the start, we will introduce and analyze the properties of a binomial distribution.\n",
    "Subsequently, we introduce and analyze normal distributions.\n",
    "Finally, we will work with probability rules.\n",
    "\n",
    "### **Table of Contents**\n",
    "1. [Discrete Probabilities](#discrete-probabilities)\n",
    "2. [Continuous Probabilities](#continuous-probabilities)\n",
    "3. [Probability Rules](#probability-rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a714745d-6c84-452f-b796-681088b60161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from ipywidgets import interactive, FloatSlider, IntSlider"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f249219c",
   "metadata": {},
   "source": [
    "### **1. Discrete Probabilities** <a class=\"anchor\" id=\"discrete-probabilities\"></a>\n",
    "\n",
    "A discrete random variable $X$ taking values in the set $X(\\Omega) = \\{0, \\dots, n\\}, n \\in \\mathbb{N}_{\\geq 0}$ is said to be binomially distributed $X \\sim \\mathrm{Bin}(n, p)$ with $n$ as the number of trials and $p \\in [0, 1]$ as the success probability, if the *probability mass function (PMF) or probability distribution* $P(X)$ can be denoted by \n",
    "\n",
    "$P(X=x)= \\binom{n}{x} \\cdot p^x \\cdot (1-p)^{(n-x)}, x \\in X(\\Omega)$\n",
    "\n",
    "#### **Questions:**\n",
    "1. (a) How can we prove that the PMF $P(X)$ of a binomially distributed variable $X \\sim \\mathrm{Bin}(n,p)$ is normalized? \n",
    "\n",
    "    *Remark: One can use the binomial expansion known from elementary algebra.* \n",
    "    \n",
    "    Binomial expansion:\n",
    "    $\\forall x, y \\in \\mathbb{R}, \\forall z \\in \\mathbb{N}_{\\geq 0}: (x+y)^z = \\sum_{k=0}^z \\binom{z}{k} \\cdot x^k \\cdot y^{z-k}$\n",
    "    \n",
    "    $\\sum_{x \\in X(\\Omega)} P(X=x) = \\sum_{x \\in X(\\Omega)} \\binom{n}{x} \\cdot p^x \\cdot (1-p)^{n-x} = (p+(1-p))^n = 1^n = 1$\n",
    "    \n",
    "    (b) Define the probability space $(\\Omega, \\mathcal{A}, P)$ and a random variable $X$ modeling the number of heads when tossing a coin five times.\n",
    "    \n",
    "    $\\Omega = \\{H, T\\}^5$,\n",
    "    \n",
    "    $\\mathcal{A} = 2^\\Omega$,\n",
    "    \n",
    "    $P(A) = \n",
    "    \\begin{cases}\n",
    "        0 & \\text{if } A = \\varnothing ,\\\\\n",
    "        0.5^5 & \\text{if } |A| = 1,\\\\\n",
    "        \\sum_{w \\in A} P(\\{w\\}) & \\text{else.}\n",
    "    \\end{cases}$\n",
    "    \n",
    "    $X((w_1, \\dots, w_N)^T)= \\sum_{n=1}^N \\delta(w_n=H)$\n",
    "    \n",
    "    (c) How can we derive the expected value $E(X)$ and the variance $V(X)$ of a binomially distributed variable $X \\sim \\mathrm{Bin}(n,p)$? \n",
    "\n",
    "    *Remark: A binomially distributed random variable can be represented through a sum of independent random variables following the same Bernoulli distribution, i.e.,* \n",
    "    $$X = \\sum_{i=1}^n X_i \\text{ with } \\forall i \\in \\{1, \\dots, n\\}: X_i \\sim \\mathrm{Bern}(p).$$\n",
    "\n",
    "    $E(X) = E(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n(E(x_i)) = \\sum_{i=1}^n p = n \\cdot p$\n",
    "    \n",
    "    $V(X)= \\dots =n \\cdot p \\cdot (1-p)$  // SKIPPED, discussed next exercise\n",
    "\n",
    "    (d) How can we estimate the expected value and variance of the Binomial distribution, when we have made the observations $x_1, \\dots, x_N \\in \\{0, \\dots, n\\}$, $N \\in \\mathbb{N}_{>0}$?\n",
    "\n",
    "    // SKIPPED, discussed next exercise\n",
    "    \n",
    "    Empirical Mean (Slide 49)\n",
    "    \n",
    "    Empirical Variance (Slide 50)\n",
    "\n",
    "In the following, we use the [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) package to plot the binomial distribution for different values of $n$ and $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc81669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab2dd657e8041a99ad705e2cf5821d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='n', min=1), FloatSlider(value=0.5, description='p', maxâ€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_binomial_distribution(n, p, N):\n",
    "    \"\"\"\n",
    "    Visualizes the binomial distribution for varying parameters and\n",
    "    indicates summary statistics, i.e., (empirical) mean and (empirical variance).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Positive number of trials within one binomial experiment.\n",
    "    p : float in [0, 1]\n",
    "        Success probability.\n",
    "    N : int\n",
    "        Positive number of repeated binomial experiments.\n",
    "    \"\"\"\n",
    "    # Compute the expected value `mean` and the variance `var`.\n",
    "    mean = stats.binom.mean(n,p)\n",
    "    var = stats.binom.var(n,p)\n",
    "    \n",
    "    # Draw N observations `x_sampled` from the PMF P(X) with X ~ Bin(n, p).\n",
    "    x_sampled = stats.binom.rvs(n, p, size=N)\n",
    "    \n",
    "    # Estimate the expected value `mean_est` and variance `var_est` using the observations.\n",
    "    mean_est = (1/N) * np.sum(x_sampled)\n",
    "    var_est = (1/(N-1)) * np.sum((x_sampled - mean_est)**2)\n",
    "    \n",
    "    # Create an array `x` containing the numbers {0, ..., n}.\n",
    "    x = np.arange(0, n+1)\n",
    "    \n",
    "    # Compute P(X=x) as `p_x` with x in {0, ..., n} for X ~ Bin(n, p)\n",
    "    p_x = stats.binom.pmf(x, n, p)\n",
    "    \n",
    "    # Plot results.\n",
    "    plt.bar(x, p_x, label=f'PMF')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$P(X=x)$')\n",
    "    plt.title(\n",
    "        \"$X \\sim \\mathrm{Bin}(\" \n",
    "        + str(n) + \",\" \n",
    "        + str(p) \n",
    "        + \")$ with \\n$E(X) =$\" \n",
    "        + str(np.round(mean, 2)) \n",
    "        + \", $\\overline{x} =$\" \n",
    "        + str(np.round(mean_est, 2)) \n",
    "        + \", \\n$V(X) = $\" \n",
    "        + str(np.round(var, 2))\n",
    "        + \", $\\overline{\\sigma}^2 =$\" \n",
    "        + str(np.round(var_est, 2)) \n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "interactive(\n",
    "    visualize_binomial_distribution, \n",
    "    n=IntSlider(value=10, min=1, max=100),\n",
    "    p=FloatSlider(value=0.5, min=0.0, max=1.0),\n",
    "    N=IntSlider(value=10, min=2, max=1000)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1152ed4",
   "metadata": {},
   "source": [
    "#### **Questions:**\n",
    "1. (c) How does the sample size $N$ affect the estimates of the empirical mean and variance?\n",
    "   \n",
    "    The greater N is, the closer the estimates get to the expected mean and variance.\n",
    "\n",
    "\n",
    "### **2. Continuous Probabilities** <a class=\"anchor\" id=\"continuous-probabilities\"></a>\n",
    "\n",
    "A continuous random variable $X$ taking any value in the set $X(\\Omega) = \\mathbb{R}$ is said to be rectangularly (uniformly) distributed $X \\sim \\mathrm{Rect}(a, b)$ with $a, b \\in \\mathbb{R}, a < b$ as its parameters, if the *probability density function (PDF)* $f(X)$ can be denoted by \n",
    "\n",
    "TODO\n",
    "\n",
    "#### **Questions:**\n",
    "2. (a) How can we show that the PDF of the rectangularly distributed random variable $X \\sim \\mathrm{Rect}(a,b)$ is a valid PDF?\n",
    "   \n",
    "    TODO\n",
    "\n",
    "**Definition 2.17** <font color='red'>**Multivariate Normal Distribution**</font> \n",
    "\n",
    "A multivariate continuous random variable $\\mathbf{X} = (X_1, \\dots, X_D)^\\mathrm{T}, D \\in \\mathbb{N}_{>0}$ follows a *multivariate normal distribution* with the mean $\\boldsymbol{\\mu} \\in \\mathbb{R}^D$ and the symmetric, positive-definite covariance matrix $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{D \\times D}$\n",
    "if the PDF is defined through\n",
    "$$\n",
    "f(\\mathbf{X}=\\mathbf{x}) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}} \\cdot \\frac{1}{|\\boldsymbol{\\Sigma}|^{\\frac{1}{2}}} \\cdot \\exp\\left(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^\\mathrm{T} \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right),\n",
    "$$\n",
    "where $|\\boldsymbol{\\Sigma}|$ denotes the determinant of the covariance matrix and $\\boldsymbol{\\Sigma}^{-1}$ its inverse.\n",
    "\n",
    "**Remarks:**\n",
    "- The normal distribution, also known as the Gaussian distribution, is one of the most important probability distributions in stochastic. It is used in a wide range of fields to model the distribution of random variables that arise in nature, such as the heights of people, the weights of objects, and the errors in measurements.\n",
    "- We denote $\\mathbf{X} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ to indicate that a random variable follows a multivariate normal distribution.\n",
    "- The inverse of the covariance matrix, i.e., $\\boldsymbol{\\Sigma}^{-1}$, is also named precision matrix.\n",
    "\n",
    "#### **Questions:**\n",
    "2. (b) Which form does the PDF of a univariate normal distribution ($D=1$) take?\n",
    "\n",
    "TODO\n",
    "$$\n",
    "f(\\mathbf{X}=\\mathbf{x}) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}} \\cdot \\frac{1}{|\\boldsymbol{\\Sigma}|^{\\frac{1}{2}}} \\cdot \\exp\\left(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^\\mathrm{T} \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9992e9ef-a436-4dba-8ac3-5226b1ba37f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81938cb32b38413faa206eb998014dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='mu', max=2.0, min=-2.0), FloatSlider(value=1.0, descâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_normal_distribution(mu, sigma, N):\n",
    "    \"\"\"\n",
    "    Visualizes the univariate normal distribution for varying parameters and\n",
    "    indicates summary statistics, i.e., (empirical) mean and (empirical) variance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mu : float\n",
    "        Mean of the normal distribution.\n",
    "    sigma : float\n",
    "        Standard deviation of the normal distribution.\n",
    "    N : int\n",
    "        Positive number of repeated binomial experiments.\n",
    "    \"\"\"\n",
    "    # Draw N observations `x_sampled` from the pdf f(X) with X ~ N(mu, sigma**2).\n",
    "    x_sampled = stats.norm(mu, sigma).rvs(N)\n",
    "    \n",
    "    # Estimate the expected value `mean_est` and variance `var_est` using the observations.\n",
    "    mean_est = (1/N) * x_sampled.sum()\n",
    "    var_est = (1/(N-1)) * ((x_sampled - mean_est)**2).sum()\n",
    "    \n",
    "    # Create an array `x` of 1000 linearly distributed values in the range [-5, 5].\n",
    "    x = np.linspace(-5, 5, 1000)\n",
    "    \n",
    "    # Compute the density f(X=x) as `f_x` for all values in `x`.\n",
    "    f_x = stats.norm(mu, sigma).pdf(x)\n",
    "\n",
    "    # Plot the f(x) for mu and sigma over all values in `x`.\n",
    "    plt.plot(x, f_x, label=f'PDF')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$f(X=x)$')\n",
    "    plt.title(\n",
    "        \"$X \\sim \\mathcal{N}(\" \n",
    "        + str(mu) + \",\" \n",
    "        + str(np.round(sigma**2, 2)) \n",
    "        + \")$ with \\n$\\overline{x} =$\" \n",
    "        + str(np.round(mean_est, 2)) \n",
    "        + \", \\n$\\overline{\\sigma}^2 =$\" \n",
    "        + str(np.round(var_est, 2)) \n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "interactive(\n",
    "    visualize_normal_distribution, \n",
    "    mu=FloatSlider(value=0, min=-2, max=2),\n",
    "    sigma=FloatSlider(value=1, min=0.1, max=2),\n",
    "    N=IntSlider(value=10, min=2, max=1000)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3224cab8",
   "metadata": {},
   "source": [
    "#### **Questions:**\n",
    "2. (c) How do the parameters $\\mu$ and $\\sigma^2$ affect the shape of the PDF of the normal distribution?\n",
    "\n",
    "$\\mu$ : shifts to left/right\n",
    "$\\sigma$ schmaler/breiter\n",
    "\n",
    "\n",
    "Even for the univariate case $D=1$, the CDF of the normal distribution cannot be expressed in terms of elementary functions. However, many numerical approximations are known. A typical approach is to transform any univariate normal distribution into a standard normal distribution.\n",
    "\n",
    "**Definition 2.18** <font color='red'>**Standard Normal Distribution**</font> \n",
    "\n",
    "The univariate normal distribution $\\mathcal{N}(0, 1)$ is called *standard normal distribution* and its CDF is denoted as $\\Phi: \\mathbb{R} \\rightarrow [0, 1]$.\n",
    "\n",
    "For computing the probabilities of a random variable $X \\sim \\mathcal{N}(0, 1)$, there are [lookup tables](https://en.wikipedia.org/wiki/Standard_normal_table) and any random variable following a univariate normal distribution can be transformed to follow the standard normal distribution.\n",
    "\n",
    "**Theorem 2.10** <font color='red'>**Transformation to a Standard Normal Distribution**</font> \n",
    "\n",
    "Let $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ be a random variable following the univariate normal distribution $\\mathcal{N}(0, 1)$. Then, we get:\n",
    "$$\n",
    "F(X=x) = \\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right).\n",
    "$$\n",
    "\n",
    "**Remark**: The standard normal distribution is symmetric such that $\\forall x \\in \\mathbb{R}: \\Phi(-x) = 1 - \\Phi(x)$. \n",
    "\n",
    "#### **Questions:**\n",
    "\n",
    "2. (d) Does it hold that for a random variable $X$ with $E(X)=\\mu$ and $V(X)=\\sigma^2$, we get $E(Z)=0$ and $V(Z)=1$ for $Z=\\frac{(X-\\mu)}{\\sigma}$? Prove your answer.\n",
    "\n",
    "   TODO\n",
    "   \n",
    "   (e) What is the probability of $1 \\leq X < 6$ for $X \\sim \\mathcal{N}(2, 4)$? Answer this question by using the standard normal distribution with a [lookup table](https://en.wikipedia.org/wiki/Standard_normal_table).\n",
    "   \n",
    "   TODO\n",
    "   \n",
    "   \n",
    "In the following, we use the [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) package to verify the result in question 2(d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9131300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(1 <= X < 6) = 0.9772498680518208 - 0.3085375387259869 = 0.6687123293258339\n"
     ]
    }
   ],
   "source": [
    "# Compute the probability P(1 <= X < 6) for X ~ N(2, 4).\n",
    "p_6 = stats.norm(2, np.sqrt(4)).cdf(6)\n",
    "p_1 = stats.norm(2, np.sqrt(4)).cdf(1)\n",
    "p = p_6 - p_1\n",
    "print(f\"P(1 <= X < 6) = {p_6} - {p_1} = {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27383a",
   "metadata": {},
   "source": [
    "One of the main reasons the normal distribution is so widely used is due to the central limit theorem.\n",
    "\n",
    "**Theorem 2.11** <font color='red'>**Central Limit Theorem**</font> \n",
    "\n",
    "Let $X_1, X_2, \\dots $ be a sequence of i.i.d. random variables. Further, assume that the expected value $E(X_1) = \\mu$ and the variance $\\sigma^2 = V(X_1)$ exist. Then, the random variable $S_N = X_1 + \\dots + X_N, N \\in \\mathbb{N}_{>0}$ has an expected value of $E(S_N) = N\\mu$ and a variance of $V(S_N) = N\\sigma^2$. If one forms from it the standardized random variable\n",
    "$$\n",
    "Z_N = \\frac{S_N - N\\mu}{\\sigma\\sqrt{N}},\n",
    "$$\n",
    "then the central limit theorem states that the CDF of $Z_N$ for $N \\rightarrow \\infty$ pointwisely converges to the CDF $\\Phi$ of the standard normal distribution $\\mathcal{N}(0,1)$:\n",
    "$$\n",
    "\\lim_{N \\rightarrow \\infty} F(Z_n = z) = \\Phi(z).\n",
    "$$\n",
    "\n",
    "**Remarks:** \n",
    "- Intuitively, the theorem states that, under certain conditions, the sum of numerous i.i.d. random variables tends towards a normal distribution. This makes the normal distribution a natural choice for modeling a wide range of phenomena that arise in nature.\n",
    "- The earliest version of this theorem, that the normal distribution may be used as an approximation to the binomial distribution, is the de Moivreâ€“Laplace theorem.\n",
    "\n",
    "**Theorem 2.12** <font color='red'>**De Moivre-Laplace Theorem**</font> \n",
    "\n",
    "Let $X \\sim \\mathrm{Bin}(n, p)$ be a random variable with the expected value $E(X)=\\mu$ and the variance $V(X) = \\sigma$. Then, for a sufficiently large $n$ we can make the following approximation:\n",
    "$$\n",
    "F(X=x) = P(X \\leq x) \\approx \\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right).\n",
    "$$\n",
    "\n",
    "**Remark**: The following condition can serve as a rule of thumb for the application of the de Moivre-Laplace theorem\n",
    "$$\n",
    "V(X) = n \\cdot p \\cdot (1-p) > 9.\n",
    "$$\n",
    "\n",
    "In the following, we use the [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) package to compare the actual CDF of the binomial distribution with the one approximated via the de Moive-Laplace theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6affa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fa6477f5bd4e9c9706a95a221fd28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='n', min=1), FloatSlider(value=0.5, description='p', maxâ€¦"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_de_moive_laplace_theorem(n, p):\n",
    "    \"\"\"\n",
    "    Compares the CDF of the binomial distribution with the\n",
    "    approximation using the de Moivre-Laplace theorem.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Positive number of trials within one binomial experiment.\n",
    "    p : float in [0, 1]\n",
    "        Success probability.\n",
    "    \"\"\"\n",
    "    # Compute the expected value `mean` and the variance `var`.\n",
    "    mean = n*p\n",
    "    var = n*p*(1-p)\n",
    "    \n",
    "    # Create `x_bin` array containing the numbers {0, ..., n}.\n",
    "    x_bin = np.arange(n+1)\n",
    "     \n",
    "    # Compute F(X=x) as `f_x_bin` with x in {0, ..., n} for X ~ Bin(n, p)\n",
    "    f_x_bin = stats.binom(n,p).cdf(x_bin)\n",
    "    \n",
    "    # Create an array `x_norm` containing 10*n values evenly distributed across the interval [0, n].\n",
    "    x_norm = np.linspace(0, n, 10*n)\n",
    "    \n",
    "    # Use the de Moivre-Laplace theorem to approximate `f_x_bin` via `f_x_norm`.\n",
    "    f_x_norm = stats.norm(0,1).cdf((x_norm-mean)/np.sqrt(var))\n",
    "    \n",
    "    # Plot results.\n",
    "    plt.bar(x_bin, f_x_bin, label=f'CDF of binomial distribution', color=\"blue\", alpha=0.5)\n",
    "    plt.plot(x_norm, f_x_norm, label=f'CDF of normal distribution', color=\"red\")\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$F(X=x)$')\n",
    "    plt.title(\n",
    "        \"$X \\sim \\mathrm{Bin}(\" \n",
    "        + str(n) + \",\" \n",
    "        + str(p) \n",
    "        + \")$ with \\n$E(X) =$\" \n",
    "        + str(np.round(mean, 2)) \n",
    "        + \", \\n$V(X) = $\" \n",
    "        + str(np.round(var, 2))\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "interactive(\n",
    "    visualize_de_moive_laplace_theorem, \n",
    "    n=IntSlider(value=10, min=1, max=100),\n",
    "    p=FloatSlider(value=0.5, min=0.0, max=1.0),\n",
    "    N=IntSlider(value=10, min=2, max=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4636826",
   "metadata": {},
   "source": [
    "For the multivariate normal distribution, the covariance matrix $\\boldsymbol{\\sigma}$ plays a critical role regarding the distribution's shape. For a better understanding, we use the [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) package to study the influence of this matrix in the bivariate ($D=2$) case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2deedd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5116878b5238430ca166c125da2332df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='mean_x', max=4.0, min=-4.0), FloatSlider(value=0.0, â€¦"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_bivariate_normal_distribution(mean_x, mean_y, var_x, var_y, cov_xy, N):\n",
    "    \"\"\"\n",
    "    Visualizes the bivariate normal distribution for varying parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mean_x : float\n",
    "        Mean of the normal distribution in the x-dimension.\n",
    "    mean_y : float\n",
    "        Mean of the normal distribution in the y-dimension\n",
    "    var_x : float\n",
    "        Variance of the normal distribution in the x-dimension.\n",
    "    var_y : float\n",
    "        Variance of the normal distribution in the y-dimension.\n",
    "    cov_xy : float\n",
    "        Covariance of the normal distribution between the x- and y-dimension.\n",
    "    N : int\n",
    "        Positive number of observations to be drawn from the normal distribution.\n",
    "    \"\"\"\n",
    "    # Create the `mu` vector as numpy.ndarray.\n",
    "    mu = np.array([mean_x, mean_y])\n",
    "    \n",
    "    # Create the `Sigma` matrix as numpy.ndarray.\n",
    "    Sigma = np.array([[var_x, cov_xy], [cov_xy, var_y]])\n",
    "    \n",
    "    # Print error message if `Sigma` is not positiv definite.\n",
    "    if np.any(np.linalg.eigvals(Sigma) < 0):\n",
    "        print(\"Sigma is not positive definite\")\n",
    "        return\n",
    "    \n",
    "    # Draw N observations `X_sampled` from the PDF f(X) with X ~ Norm(mu, Sigma).\n",
    "    X_sampled = stats.multivariate_normal(mu, Sigma).rvs(N)\n",
    "    \n",
    "    # Plot sampled observations.\n",
    "    plt.scatter(X_sampled[:, 0], X_sampled[:, 1], label=\"sampled observations\")\n",
    "    plt.xlim([-10, 10])\n",
    "    plt.ylim([-10, 10])\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$y$')\n",
    "    plt.title(\n",
    "        \"$X \\sim \\mathcal{N}(\\mathbf{\\mu}, \\mathbf{\\Sigma})$\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "interactive(\n",
    "    visualize_bivariate_normal_distribution, \n",
    "    mean_x=FloatSlider(value=0, min=-4, max=4),\n",
    "    mean_y=FloatSlider(value=0, min=-4, max=4),\n",
    "    var_x=FloatSlider(value=1, min=0.1, max=4),\n",
    "    var_y=FloatSlider(value=1, min=0.1, max=4),\n",
    "    cov_xy=FloatSlider(value=0, min=-4, max=4),\n",
    "    N=IntSlider(value=1000, min=2, max=10000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6981d10",
   "metadata": {},
   "source": [
    "#### **Questions:**\n",
    "2. (f) How do the elements of the covariance matrix $\\boldsymbol{\\Sigma}$ affect the shape of the PDF of the normal distribution?\n",
    "\n",
    "   TODO\n",
    "   \n",
    "### **3. Probability Rules** <a class=\"anchor\" id=\"probability-rules\"></a>\n",
    "Consider the following bivariate PMF $P(X, Y)$ of two discrete random variables $X$ and $Y$ with $X(\\Omega) = \\{x_1, x_2, x_3, x_4\\}$ and $Y(\\Omega) = \\{y_1, y_2, y_3\\}$:\n",
    "\n",
    "| $P(X=x_i, Y=y_i)$      | $x_1$ | $x_2$ | $x_3$ | $x_4$ |\n",
    "|------------------------|-------|-------|-------|-------|\n",
    "| $y_1$                  | 0.01  | 0.2   | 0.1   | 0.1   |\n",
    "| $y_2$                  | 0.05  | 0.05  | 0.07  | 0.2   |\n",
    "| $y_3$                  | 0.1   | 0.03  | 0.05  | 0.04  |\n",
    "\n",
    "#### **Questions:**\n",
    "3. (a) How can we compute the marginal PMFs $P(X)$ and $P(Y)$?\n",
    "    \n",
    "    TODO\n",
    "    \n",
    "   (b) How can we compute the conditional PMFs $P(X \\mid Y=y_1)$ and $P(Y \\mid X=x_3)$?\n",
    "    \n",
    "    TODO\n",
    "    \n",
    "     (b) Are the random variables $X$ and $Y$ statistically independent?\n",
    "    \n",
    "    TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
